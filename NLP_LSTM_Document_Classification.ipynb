{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hamza-Chekireb/Artificial-Intelligence-Data-Science-Data-Analysis-Portfolio/blob/main/NLP_LSTM_Document_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2NpYFshs7xG"
      },
      "source": [
        "#### 1. Document classification with LSTM network:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qodeGFUs7xH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings    \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets.reuters import load_data, get_word_index       # Reuters news data. \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, SimpleRNN, LSTM, Embedding\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing import sequence\n",
        "from keras.optimizers import Adam, RMSprop, SGD\n",
        "warnings.filterwarnings('ignore')                  # Turn the warnings off.\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-soUyl4Zs7xJ"
      },
      "source": [
        "#### 1.1. Read in the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2fVuDnMs7xK"
      },
      "outputs": [],
      "source": [
        "n_words = 1000                                        # Size of the vocabulary.\n",
        "(X_train, y_train), (X_test, y_test) = load_data(num_words = n_words, test_split = 0.3)\n",
        "n_train_size = X_train.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MM4LWSTrs7xK"
      },
      "outputs": [],
      "source": [
        "# Check for the shapes.\n",
        "print(\"-\"*50)\n",
        "print(\"Training data X shape: {}\".format(X_train.shape))\n",
        "print(\"Training data y shape: {}\".format(y_train.shape))\n",
        "print(\"-\"*50)\n",
        "print(\"Test data X shape: {}\".format(X_test.shape))\n",
        "print(\"Test data y shape: {}\".format(y_test.shape))\n",
        "print(\"-\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KG8s-yZfs7xL"
      },
      "source": [
        "#### 1.2. Explore the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0xmWpj9s7xL"
      },
      "outputs": [],
      "source": [
        "# Number of unique values of y = Number of categories of the newswires.\n",
        "n_cat = pd.Series(y_train).nunique()\n",
        "n_cat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgTAGN8ns7xM"
      },
      "outputs": [],
      "source": [
        "# Print out an observation (document) contained in X.\n",
        "# It is encoded as integers (indices).\n",
        "print(X_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bmceBnWs7xM"
      },
      "outputs": [],
      "source": [
        "# Let's check for length of the first 100 documents.\n",
        "# We notice that the length is not uniform.\n",
        "print([len(a) for a in X_train[0:100]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLRz6U-5s7xN"
      },
      "outputs": [],
      "source": [
        "# Download the dictionary to translate the indices.\n",
        "my_dict = get_word_index(path='reuters_word_index.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NsSfKTws7xN"
      },
      "outputs": [],
      "source": [
        "# To view the dictionary.\n",
        "# my_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pV9dDXMvs7xO"
      },
      "outputs": [],
      "source": [
        "# Exchange the 'key' and 'value'.\n",
        "my_dict_inv = {v:k for k,v in my_dict.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCDZ6B0bs7xO"
      },
      "outputs": [],
      "source": [
        "# Translate each document.\n",
        "i_news = 10                                        # Document number that can be changed at will.\n",
        "news = list(pd.Series(X_train[i_news]).apply(lambda x: my_dict_inv[x]))\n",
        "print(' '.join(news))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mq6kDfqYs7xP"
      },
      "source": [
        "#### 1.3. Data preprocessing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trlh5ZBVs7xP"
      },
      "outputs": [],
      "source": [
        "# Padding: newswire lengths are uniformly matched to maxlen.\n",
        "# Cut away if longer than maxlen and fill with 0s if shorter than maxlen.\n",
        "X_train = sequence.pad_sequences(X_train, maxlen = 100)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen = 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hKr_1N5s7xP"
      },
      "outputs": [],
      "source": [
        "# Apply one-hot-encoding to the y variable.\n",
        "y = np.concatenate([y_train,y_test],axis=0)\n",
        "y = to_categorical(y,46)\n",
        "y_train = y[:n_train_size,:]\n",
        "y_test = y[n_train_size:,:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTU_tn3ws7xQ"
      },
      "source": [
        "#### 1.4. Define the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwE3QESSs7xQ"
      },
      "outputs": [],
      "source": [
        "n_neurons = 100                   # Neurons within each memory cell.\n",
        "n_input = 100                     # Dimension of the embeding space. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SX-vAtu4s7xR"
      },
      "outputs": [],
      "source": [
        "# LSTM network model.\n",
        "my_model = Sequential()\n",
        "my_model.add(Embedding(n_words, n_input))           # n_words = vocabulary size, n_input = dimension of the embedding space.\n",
        "my_model.add(LSTM(units=n_neurons, return_sequences=False, input_shape=(None, n_input), activation='tanh'))\n",
        "my_model.add(Dense(n_cat, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PlmlPI5s7xR"
      },
      "outputs": [],
      "source": [
        "# View the summary.\n",
        "my_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kajosDZ3s7xR"
      },
      "source": [
        "#### 1.5. Define the optimizer and compile:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCRwI6H7s7xS"
      },
      "outputs": [],
      "source": [
        "n_epochs = 20                      # Number of epochs.\n",
        "batch_size = 20                    # Size of each batch.\n",
        "learn_rate = 0.001                 # learning rate.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntVRA-WIs7xS"
      },
      "outputs": [],
      "source": [
        "# Optimizer and compilation.\n",
        "my_optimizer=Adam(lr=learn_rate)\n",
        "my_model.compile(loss = \"categorical_crossentropy\", optimizer = my_optimizer, metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFWwfukCs7xT"
      },
      "source": [
        "#### 1.6. Train the model and visualize the history:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxH5oStos7xU"
      },
      "outputs": [],
      "source": [
        "my_summary = my_model.fit(X_train, y_train, epochs=n_epochs, batch_size = batch_size, validation_split=0.2, verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqaEWfMHs7xV"
      },
      "outputs": [],
      "source": [
        "plt.plot(my_summary.history['accuracy'], c=\"b\")\n",
        "plt.plot(my_summary.history['val_accuracy'], c=\"g\")\n",
        "plt.title('Training History')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITIl1ZDrs7xV"
      },
      "source": [
        "#### 1.7. Testing: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOaBt0Eks7xV"
      },
      "outputs": [],
      "source": [
        "ACC = my_model.evaluate(X_test, y_test, verbose=0)[1]    \n",
        "print(\"Test Accuracy : {}\".format(np.round(ACC,3)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByB6hP-9s7xW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}